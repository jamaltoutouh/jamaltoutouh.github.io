<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="http://localhost:4000//assets/xslt/rss.xslt" ?>
<?xml-stylesheet type="text/css" href="http://localhost:4000//assets/css/rss.css" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>NeCOL</title>
		<description>ESTA ES LA DESCRIPCION»Feeling Responsive« is a responsive theme for Jekyll based on the fabulous foundation framework with beautiful typography and a bright color palette.</description>
		<link>http://localhost:4000//</link>
		<atom:link href="http://localhost:4000//feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>GECCO Paper Accepted</title>
				<link>http://localhost:4000//publications/gecco-accepted/</link>
				<pubDate>Thu, 11 Apr 2019 00:00:00 -0400</pubDate>
				<description>&lt;p&gt;We are happy to inform that our paper &lt;em&gt;Spatial Evolutionary Generative Adversarial Networks&lt;/em&gt; has been accepted as a FULL PAPER to be presented during &lt;a href=&quot;https://gecco-2019.sigevo.org/&quot; title=&quot;GECCO 2019&quot;&gt;GECCO 2019&lt;/a&gt;. GECCO is one of the most important conferences in the field of evolutionary computation.&lt;/p&gt;

&lt;h3 id=&quot;spatial-evolutionary-generative-adversarial-networks&quot;&gt;Spatial Evolutionary Generative Adversarial Networks&lt;/h3&gt;
&lt;h4 id=&quot;abstract&quot;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Generative adversary networks (GANs) suffer from training pathologies such as instability and mode collapse. These pathologies mainly arise from a lack of diversity in their adversarial interactions. Evolutionary generative adversarial networks apply the principles of evolutionary computation to mitigate these problems. We hybridize two of these approaches that promote training diversity. One, E-GAN, at each batch, injects mutation diversity by training the (replicated) generator with three independent objective functions then selecting the resulting best performing generator for the next batch. The other, Lipizzaner, injects population diversity by training a two-dimensional grid of GANs with a distributed evolutionary algorithm that includes neighbor exchanges of additional training adversaries, performance based selection and population-based hyper-parameter tuning. We propose to combine mutation and population approaches to diversity improvement. We contribute a superior evolutionary GANs training method, Mustangs, that eliminates the single loss function used across Lipizzaner ’s grid. Instead, each training round, a loss function is selected with equiprobability, from among the three E-GAN uses. Experimental analyses on a standard benchmark, MNIST, demonstrate that Mustangs provides a statistically faster training method resulting in more accurate networks.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//publications/gecco-accepted/</guid>
			</item>
		
			<item>
				<title>Paper Submitted to GECCO</title>
				<link>http://localhost:4000//publications/gecco-submitted/</link>
				<pubDate>Wed, 06 Feb 2019 00:00:00 -0500</pubDate>
				<description>&lt;p&gt;We are glad to inform that we have been able to prepare and show some interesting results about our research in fostering diversity when training genertive adversarial networks applying a coevolutionary mehtod. In this case, we have increased the diversity by applying different mutation operators (loss functions) during the trainig process. The proposed framework is named &lt;strong&gt;Mustangs&lt;/strong&gt; and the paper is entitled &lt;em&gt;Spatial Evolutionary Generative Adversarial Networks&lt;/em&gt;. We will be really happy if we are able to present the paper during &lt;a href=&quot;https://gecco-2019.sigevo.org/&quot; title=&quot;GECCO 2019&quot;&gt;GECCO 2019&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;spatial-evolutionary-generative-adversarial-networks&quot;&gt;Spatial Evolutionary Generative Adversarial Networks&lt;/h3&gt;
&lt;h4 id=&quot;abstract&quot;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Generative adversary networks (GANs) suffer from training pathologies such as instability and mode collapse. These pathologies mainly arise from a lack of diversity in their adversarial interactions. Evolutionary generative adversarial networks apply the principles of evolutionary computation to mitigate these problems. We hybridize two of these approaches that promote training diversity. One, E-GAN, at each batch, injects mutation diversity by training the (replicated) generator with three independent objective functions then selecting the resulting best performing generator for the next batch. The other, Lipizzaner, injects population diversity by training a two-dimensional grid of GANs with a distributed evolutionary algorithm that includes neighbor exchanges of additional training adversaries, performance based selection and population-based hyper-parameter tuning. We propose to combine mutation and population approaches to diversity improvement. We contribute a superior evolutionary GANs training method, Mustangs, that eliminates the single loss function used across Lipizzaner ’s grid. Instead, each training round, a loss function is selected with equiprobability, from among the three E-GAN uses. Experimental analyses on a standard benchmark, MNIST, demonstrate that Mustangs provides a statistically faster training method resulting in more accurate networks.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//publications/gecco-submitted/</guid>
			</item>
		
			<item>
				<title>NeCOL Project Website Launched</title>
				<link>http://localhost:4000//general/launched/</link>
				<pubDate>Sat, 15 Sep 2018 00:00:00 -0400</pubDate>
				<description>&lt;p&gt;NeCOL is a decir quien financia, las fechas, etc. y el tipo de cosas que vamos a publicar.&lt;/p&gt;
</description>
				<guid isPermaLink="true">http://localhost:4000//general/launched/</guid>
			</item>
		
	</channel>
</rss>
